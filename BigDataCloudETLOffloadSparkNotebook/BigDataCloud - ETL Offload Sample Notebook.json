{"paragraphs":[{"text":"%md\n","user":"anonymous","dateUpdated":"May 8, 2018 4:34:43 PM","config":{},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525797283815_1021351128","id":"20180508-163443_1699029375","dateCreated":"May 8, 2018 4:34:43 PM","status":"READY","progressUpdateIntervalMs":500},{"text":"%md\n \n Copyright Â© 2018, Oracle and/or its affiliates. All rights reserved. \nThe Universal Permissive License (UPL), Version 1.0 \nETL Offload Example - \n\nThe sample Spark code below reads 3 files from ObjectStorage (CUSTOMER, ORDERS, PRODUCTS, ORDER_LINES) then joins the files together and performs some sales analysis by Product Family and Year.\nThe code stores the output in multiple formats back into ObjectStorage.\n\nThe second paragraph shows querying the sales_analysis object and being able to graphically view the results using the Notebook","user":"anonymous","dateUpdated":"Apr 17, 2018 6:33:26 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>ETL Offload Example - </p>\n<p>The sample Spark code below reads 3 files from ObjectStorage (CUSTOMER, ORDERS, PRODUCTS, ORDER_LINES) then joins the files together and performs some sales analysis by Product Family and Year.<br/>The code stores the output in multiple formats back into ObjectStorage.</p>\n<p>The second paragraph shows querying the sales_analysis object and being able to graphically view the results using the Notebook</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1523988498567_-728735906","id":"20180417-180818_1137101878","dateCreated":"Apr 17, 2018 6:08:18 PM","dateStarted":"Apr 17, 2018 6:33:26 PM","dateFinished":"Apr 17, 2018 6:33:26 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sql \n--DROP TABLE product\n--DROP TABLE orders\n--DROP TABLE order_lines\n--DROP TABLE sales_analysis\nshow tables\n\n","user":"anonymous","dateUpdated":"May 8, 2018 7:42:24 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"database\ttableName\tisTemporary\n\tcustfile\ttrue\n\tcustomers\ttrue\n\torders\ttrue\n\tproduct\ttrue\n\tsales_analysis\ttrue\n"}]},"apps":[],"jobName":"paragraph_1525796797812_-1732785479","id":"20180508-162637_1841259008","dateCreated":"May 8, 2018 4:26:37 PM","dateStarted":"May 8, 2018 7:42:24 PM","dateFinished":"May 8, 2018 7:42:24 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%spark\n\n// Confirm the Obj Storage folder and destination file name\n// Create a container and upload the sample files.  In this example the container name is BDCETL\n\nval Container=\"BDCETL\"\nval Directory=\"/\"\nval tablename = \"CUSTOMER_SRC_FILE.csv\"\n//val filebase = \"swift://\"+Container+\".default/\"+Directory+\"/\"+tablename\n//val filebase = \"swift://\"+Container+\".default/CUSTOMER_OUTPUT.txt\"\n\n//Load Customer File\nval customerFile= spark.read.format(\"csv\")\n  .option(\"sep\", \",\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"swift://BDCETL.default/CUSTOMER_SRC_FILE.csv\")\n\n//Regsiter as a table  \ncustomerFile.createOrReplaceTempView(\"customers\")\n//Show Customer File\n //sql(\"SELECT * FROM customers\").show()\n \n//Load ORDERS File\nval ordersFile= spark.read.format(\"csv\")\n  .option(\"sep\", \",\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"swift://BDCETL.default/ORDERS_FILE.csv\")\nordersFile.createOrReplaceTempView(\"orders\")   \n//Show ORDERS File\n//sql(\"SELECT * FROM orders\").show()\n\n//Load PRODUCT File\nval productFile= spark.read.format(\"csv\")\n  .option(\"sep\", \",\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"swift://BDCETL.default/SRC_PRODUCT.csv\")  \n//create orders SparkSQL DF  \nproductFile.createOrReplaceTempView(\"product\")\n//Show PRODUCT File\n//sql(\"SELECT * FROM product\").show()\n\n/*\n    Sales Analysis Calculation - \n            Sales by Product Family by Year\n            Prior Yr Sales Amount for the ProductFamily\n            Overall Total sales for the Yr \n            Prior 3 Yr high Sales amount for the Product Family\n*/\n val analysis =  sql(\"SELECT REGION, FAMILY as PRODUCT_FAMILY, YR as SALES_YEAR, AMT as SALES_AMT, LAG(AMT) OVER (PARTITION BY REGION, FAMILY ORDER BY YR ) as PRIOR_YR_SALES, \"\n   + \" SUM(AMT) OVER (PARTITION BY YR) as TOTAL_YR_SALES, \"\n   + \" MAX( AMT) OVER (PARTITION BY REGION, FAMILY  ORDER BY YR  ROWS 3 PRECEDING) as PRIOR_3_YR_HIGH \" \n    + \"FROM ( \" +\n    \"           SELECT c.REGION, FAMILY as FAMILY, YEAR(ORDER_DATE) as YR, SUM(AMOUNT) as AMT   \" +\n                \"FROM customers c \" +\n                \"join orders o \" +\n                \"    on c.CUSTOMER_ID = o.CUSTOMER_ID \" +\n                 \"JOIN product p  \" +\n                \"    on p.PRODUCT_ID = o.PRODUCT_ID  \" +\n                \"GROUP BY REGION, FAMILY, YEAR(ORDER_DATE) ) as DATA\") //.show()\n analysis.createOrReplaceTempView(\"sales_analysis\")\n//Output Analysis if needed\nsql(\"SELECT * FROM sales_analysis ORDER BY SALES_YEAR, PRODUCT_FAMILY\").show()\nprintln(\"================================\")\nprintln(\"Output files in multiple formats\")\n\n// save in json, parquet and csv  format.  the repartition(1) ensures that we write a single output file, which makes sense since we know the output is small\nanalysis.repartition(1).write.format(\"json\").mode(\"overwrite\").save(\"swift://BDCETL.default/JSON_OUTPUT/SALES_ANALYSIS\")\nprintln(\"JSON done\")\nanalysis.repartition(1).write.format(\"parquet\").mode(\"overwrite\").save(\"swift://BDCETL.default/PARQUET_OUTPUT/SALES_ANALYSIS\")\nprintln(\"Parquet done\")\nanalysis.repartition(1).write.format(\"csv\").mode(\"overwrite\").save(\"swift://BDCETL.default/CSV_OUTPUT/SALES_ANALYSIS\")\nprintln(\"CSV done \")\n//manually check object storage for the file\n\n ","user":"anonymous","dateUpdated":"May 8, 2018 7:09:19 PM","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nContainer: String = BDCETL\n\nDirectory: String = /\n\ntablename: String = CUSTOMER_SRC_FILE.csv\n\ncustomerFile: org.apache.spark.sql.DataFrame = [CUSTOMER_ID: int, FIRST_NAME: string ... 3 more fields]\n\nordersFile: org.apache.spark.sql.DataFrame = [ORDER_ID: int, CUSTOMER_ID: int ... 5 more fields]\n\nproductFile: org.apache.spark.sql.DataFrame = [PRODUCT_ID: int, PRODUCT_NAME: string ... 2 more fields]\n\nanalysis: org.apache.spark.sql.DataFrame = [REGION: string, PRODUCT_FAMILY: string ... 5 more fields]\n+------------+--------------+----------+-----------------+--------------+-------------------+-----------------+\n|      REGION|PRODUCT_FAMILY|SALES_YEAR|        SALES_AMT|PRIOR_YR_SALES|     TOTAL_YR_SALES|  PRIOR_3_YR_HIGH|\n+------------+--------------+----------+-----------------+--------------+-------------------+-----------------+\n|ASIA        |     Equipment|      1990|        1141148.0|          null|7.488813520000002E7|        1141148.0|\n|EUROPE      |     Equipment|      1990|        1141148.0|          null|7.488813520000002E7|        1141148.0|\n|AFRICA      |     Equipment|      1990|        2282296.0|          null|7.488813520000002E7|        2282296.0|\n|AMERICA     |     Equipment|      1990|        1141148.0|          null|7.488813520000002E7|        1141148.0|\n|MIDDLE EAST |     Equipment|      1990|        3423444.0|          null|7.488813520000002E7|        3423444.0|\n|AMERICA     |        Jewels|      1990|        2693964.0|          null|7.488813520000002E7|        2693964.0|\n|AFRICA      |        Jewels|      1990|        5387928.0|          null|7.488813520000002E7|        5387928.0|\n|EUROPE      |        Jewels|      1990|        2693964.0|          null|7.488813520000002E7|        2693964.0|\n|ASIA        |        Jewels|      1990|        2693964.0|          null|7.488813520000002E7|        2693964.0|\n|MIDDLE EAST |        Jewels|      1990|        8081892.0|          null|7.488813520000002E7|        8081892.0|\n|AMERICA     |    Sportswear|      1990|        2128301.5|          null|7.488813520000002E7|        2128301.5|\n|MIDDLE EAST |    Sportswear|      1990|        6384904.5|          null|7.488813520000002E7|        6384904.5|\n|AFRICA      |    Sportswear|      1990|        4256603.0|          null|7.488813520000002E7|        4256603.0|\n|ASIA        |    Sportswear|      1990|        2128301.5|          null|7.488813520000002E7|        2128301.5|\n|EUROPE      |    Sportswear|      1990|        2128301.5|          null|7.488813520000002E7|        2128301.5|\n|MIDDLE EAST |       Various|      1990|742351.2000000002|          null|7.488813520000002E7|742351.2000000002|\n|AMERICA     |       Various|      1990|         247450.4|          null|7.488813520000002E7|         247450.4|\n|EUROPE      |       Various|      1990|         247450.4|          null|7.488813520000002E7|         247450.4|\n|ASIA        |       Various|      1990|         247450.4|          null|7.488813520000002E7|         247450.4|\n|AFRICA      |       Various|      1990|         494900.8|          null|7.488813520000002E7|         494900.8|\n+------------+--------------+----------+-----------------+--------------+-------------------+-----------------+\nonly showing top 20 rows\n\n================================\nOutput files in multiple formats\nJSON done\nParquet done\nCSV done \n"}]},"apps":[],"jobName":"paragraph_1523655401852_1622652202","id":"20180413-213641_558005281","dateCreated":"Apr 13, 2018 9:36:41 PM","dateStarted":"May 8, 2018 7:09:19 PM","dateFinished":"May 8, 2018 7:10:22 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sql\nSELECT * \nFROM sales_analysis \nWHERE REGION like'%AFRICA%' --and PRODUCT_FAMILY = 'EQUIPMENT'\norder by 1,2,3\n","user":"anonymous","dateUpdated":"May 8, 2018 7:18:17 PM","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"lineChart":{},"stackedAreaChart":{"style":"expand"}},"commonSetting":{},"keys":[{"name":"SALES_YEAR","index":1,"aggr":"sum"}],"groups":[{"name":"PRODUCT_FAMILY","index":0,"aggr":"sum"}],"values":[{"name":"SALES_AMT","index":2,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"REGION\tPRODUCT_FAMILY\tSALES_YEAR\tSALES_AMT\tPRIOR_YR_SALES\tTOTAL_YR_SALES\tPRIOR_3_YR_HIGH\nAFRICA      \tEquipment\t1990\t2282296.0\tnull\t7.48881352E7\t2282296.0\nAFRICA      \tEquipment\t1999\t2282296.0\t2282296.0\t1.2169321969999999E8\t2282296.0\nAFRICA      \tEquipment\t2000\t2282296.0\t2282296.0\t1.965813549E8\t2282296.0\nAFRICA      \tEquipment\t2001\t4564592.0\t2282296.0\t2.0594237179999998E8\t4564592.0\nAFRICA      \tJewels\t1990\t5387928.0\tnull\t7.48881352E7\t5387928.0\nAFRICA      \tJewels\t1999\t5387928.0\t5387928.0\t1.2169321969999999E8\t5387928.0\nAFRICA      \tJewels\t2000\t5387928.0\t5387928.0\t1.965813549E8\t5387928.0\nAFRICA      \tJewels\t2001\t1.0775856E7\t5387928.0\t2.0594237179999998E8\t1.0775856E7\nAFRICA      \tSportswear\t1990\t4256603.0\tnull\t7.48881352E7\t4256603.0\nAFRICA      \tSportswear\t1999\t4256603.0\t4256603.0\t1.2169321969999999E8\t4256603.0\nAFRICA      \tSportswear\t2000\t4256603.0\t4256603.0\t1.965813549E8\t4256603.0\nAFRICA      \tSportswear\t2001\t8513206.0\t4256603.0\t2.0594237179999998E8\t8513206.0\nAFRICA      \tVarious\t1990\t494900.8\tnull\t7.48881352E7\t494900.8\nAFRICA      \tVarious\t1999\t494900.8\t494900.8\t1.2169321969999999E8\t494900.8\nAFRICA      \tVarious\t2000\t494900.8\t494900.8\t1.965813549E8\t494900.8\nAFRICA      \tVarious\t2001\t989801.6000000003\t494900.8\t2.0594237179999998E8\t989801.6000000003\nAFRICA      \tWatches\t1990\t6300306.0\tnull\t7.48881352E7\t6300306.0\nAFRICA      \tWatches\t1999\t6300306.0\t6300306.0\t1.2169321969999999E8\t6300306.0\nAFRICA      \tWatches\t2000\t6300306.0\t6300306.0\t1.965813549E8\t6300306.0\nAFRICA      \tWatches\t2001\t1.2600612E7\t6300306.0\t2.0594237179999998E8\t1.2600612E7\n"}]},"apps":[],"jobName":"paragraph_1523655425906_1392202935","id":"20180413-213705_1629897701","dateCreated":"Apr 13, 2018 9:37:05 PM","dateStarted":"May 8, 2018 7:18:17 PM","dateFinished":"May 8, 2018 7:18:24 PM","status":"FINISHED","progressUpdateIntervalMs":500},{"text":"%sql\n","user":"anonymous","dateUpdated":"Apr 17, 2018 6:26:49 PM","config":{},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1523989609393_-133354213","id":"20180417-182649_1591019131","dateCreated":"Apr 17, 2018 6:26:49 PM","status":"READY","progressUpdateIntervalMs":500}],"name":"BigDataCloud - ETL Offload Sample Notebook","id":"2DDZXAZ7A","angularObjects":{"2DCG6Z67R:shared_process":[],"2DBRKMGSY:shared_process":[],"2DBJJFE1P:shared_process":[],"2DASVKUQF:shared_process":[],"2D9NJNMH5:shared_process":[],"2DAAX8G5M:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2DBQT56Y9:shared_process":[]},"config":{},"info":{}}